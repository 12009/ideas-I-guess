## 说明

- 直接看书看不下去
- 只有边看边做笔记才有效率

[TOC]



## 架构分析

- 



## 日志采集

### 浏览器采集过程



#### 页面浏览日志采集流程



#### 页面交互日志采集



#### 页面日志的清洗和预处理



### 无线客户端采集过程

- 阿里巴巴内部使用UserTrack的SDK采集
- 用户的行为通过“事件”这一概念来描述，也作为程序处理的基本单位

#### 页面事件

#### 控件点击及其他事件

#### 特殊场景

#### 遇到的问题

##### app应用繁多

##### 设备的不同

##### 传输的透明性

#### 现阶段的挑战

## 数据同步

### 同步类型

- 直连同步
- 数据文件同步
- 数据库日志解析同步

### 直连同步

- 规范的接口API
- 动态链接库的方式连接业务库
- 因为所有类型数据库全部根据统一的api作为接口，所以比较容易转移业务

### 数据文件同步

- 定义好文件编码，大小，格式。
- 多个不同类型全部读写到一个文件服务器
- 然后在统一上传，下载，进行管理
- 可以包含一个校验文件，记录数据量大小，和数据同步准确行

### 数据库日志解析同步

- 日志文件的系统恢复用来记录数据库的操作
- 操作有：增删改查
- 所以一条记录用同一个主键，但是操作类型不一样或者说执行流程不一样。需要进行一个去重处理
  - 不过滤删除流水
  - 过滤最后一天删除流水
  - 过滤删除流水和之前的流水



### 现阶段问题

- 数据延迟
- 日志分析难度较大耗时间
- 数据漂移和遗漏，如零点的时候的增量表，该如何处理



## 阿里数据同步的解决方案

- 可以处理多样化的数据来源，各种数据库
- 处理数据量大，可以达到EB级别，同步数据达到PB级别

### 批量数据同步

- 建立一个数据仓库系统
- 需要统一数据格式，结构化的数据
- 统一可以使用SQL标准语言
- 数据类型均可以转换字符串



### DataX

- Job:数据同步作业
- Splitter:作业切分模块，将一个大任务分解成多个可以并发行的小任务
- Sub-Job：小任务
- Reader：数据读入模块
- Channel：交换数据的管道
- Writer：数据写出模块



### 实时数据同步

- 天猫双11，需要实时汇总，秒级数据刷新
- 解析mysql的binlog日志来实时获得增量的数据更新
- 通过消息订阅模式来实现数据的实时同步
- 一个数据交换中心
  - 从每台服务器源源不断读取日志数据
  - 然后解析binlog
  - 再同步到日志交换中心



### TimeTunnel

- 基于生产者，消费者和topic消息标识的消息中间件，将消息数据持久化到HBase的高可用，分布式数据交互系统
- 生产者：数据的产生端
- 消费者：数据的接收端
- 同批次



### 遇到的问题

#### 分库分表

- TDDL：taobao Distributed Data Layer,分布式数据库的访问引擎
- 解决分库分别的规则引擎问题
- 解决了SQL解析，规则计算，表名替换，选择执行单元并合并结果集的功能
- 解决数据库表的读写分离
- 主从备份，主备切换问题

#### 高效同步和批量同步

- oneclick



#### 增量与全量同步的合并



#### 同步性能的处理

#### 数据漂移的处理



## 离线数据开发

### 开发平台

- 业务迭代频繁
- 需求快速交付
- 上线频繁
- 运维任务多
- 系统环境负责

#### MaxCompute

- 共享安全，存储，数据管理和资源调度
- 客户端
  - Web：以restful api提供服务
  - SDK：封装API
  - CLT：完成project管理，DDL，DML等
  - IDE：上层可视化
- 接入层
  - 提高http
  - cache
  - 负载均衡
  - 用户认证
  - 服务访问控制
- 逻辑层
  - 用户空间和对象的管理
  - 命令的解析与执行逻辑
  - 数据对象的访问控制与授权
  - worker
  - scheduler
  - executor
- 计算层
  - 飞天内核
  - pangu分布式文件系统
  - fuxi资源调度系统
  - zuwa域名服务
  - shennong监控模块
  - OTS:OPEN TABLE SERVICE开放结构化数据服务，保存元数据内容
- 特点，也可以说这是基本要求
  - 计算性能高且便宜
  - 集群规模大且稳定性
  - 功能组间非常强大
  - 安全性高



#### 统一开发平台

- 任务开发及调式
- 测试
- 规则校验
- 发布
  - 任务运维
  - 质量监控
  - 运维监控
  - 数据管理
- D2
  - 集成任务开发，生成任务调度记大数据运维
  - 数据权限管理
  - 数据分析工作台的功能
- SQLSCAN
  - 专门检查用户编写的SQL质量差，性能低，不遵守规范等
- DQC data quality center 数据质量中心
  - 数据监控，监控数据质量并报警
  - 数据清洗，将不符合规则的数据清洗掉，保证没有脏数据
  - 强规则和弱规则，强规则会阻塞任务，弱规则只会报警
- 数据测试
  - 验证数据是否符合目标预期
  - 新增业务需求
  - 数据迁移，重构和修改
  - 数据对比：不同集群，异构数据库的表做数据对比
  - 数据分布：提取表和字段的一些特征值，并将这些特征值与预期值进行比对
  - 数据脱敏：将敏感数据模糊化。主要保证数据安全

### 任务调度系统

- 传统调度系统，设计一个有向无环图，每个节点都是一个定时任务。这就和AOV图有点关系了

#### 数据开发流程和调度系统的关系

- 需要达到一种低耦合的关系。调度系统有一个个节点任务。每次增加和删除任务，都要达到无感性

#### 调度系统设计

- 两个模块：调度引擎和执行引擎。阿里内部的phoenix engine 和 alisa
- 调度引擎之任务状态模型
  - 未运行
  - 等待运行
  - 等待资源
  - 运行中
  - 成功或者失败
- 调度引擎之工作流状态机模型
  - 人创建工作流
  - 已经创建
  - 启动
  - 运行中
  - 全部任务成功或者部分任务成功
- 调度引擎之工作原理
  - 异步处理任务调度
  - 同步处理任务调度
  - 任务事件处理器
  - DAG事件处理器
- 执行引擎之工作原理
  - 任务管理接口：供用户系统想ALISA中提交，查询和操作离线任务，并获得异步通知
  - 系统管理接口：供系统管理员进行后台管理，包括集群增加新的机器，划分资源组
  - Driver：alisa的调度器，负责接口之间的交互，任务调度，集群容灾和伸缩，负载均衡以及数据失效备份
  - Task poo：任务池中的所有管理，包括等待资源，数据质量检测，运行中，运行成功，和失败的所有任务。
  - Resource manager：关注集群整体资源的管理
  - Task container：类似于Web server，为task提供运行的容器
  - session magager：实现对task session的管理
  - Node：代表集群中的一个节点。逻辑上的节点。不是完全对应物理结构上的。一个物理机器上可以有多个node

### 调度系统的使用

- 通过配置
- 定时调度
- 周期调度
- 手动运行
- 补数据，也就是增量
- 基线管理，业务数据优先
- 监控报警



## 实时技术

### 要求





### 流式技术架构



### 流式数据模型





### 双11的挑战





